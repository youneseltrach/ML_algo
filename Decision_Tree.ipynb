{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdgb9mksraBiKQ7mzSFjvR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youneseltrach/ML_algo/blob/main/Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, I'll Implement a decision tree from scratch and use it to classify mushrooms as edible or poisonous.\n",
        "\n",
        "> The process of creating a decision tree involves these steps:\n",
        "1. Begin with all samples at the root node.\n",
        "2. Evaluate information gain for all possible feature splits, choose the highest.\n",
        "3. Divide the data set based on the chosen feature, generating left and right branches.\n",
        "4. Repeat splitting until the stopping criteria is met.\""
      ],
      "metadata": {
        "id": "ebSvVhzjfBJj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B9q-azXYe0uB"
      },
      "outputs": [],
      "source": [
        "# Import all the packages that we will need during this assignment\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Calculate the Entropy\n",
        "Write a helper function, `compute_entropy`, to calculate the entropy (impurity measure) at a node.\\\n",
        "The entropy is then calculated as\n",
        "\n",
        "$$H(p) = -p \\text{log}_2(p) - (1- p) \\text{log}_2(1- p)$$\n",
        "\n",
        "Where : 𝑝 is the fraction/probabilty of examples that have value = 1 in y"
      ],
      "metadata": {
        "id": "MB8ahHNFjloE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_entropy(y):  \n",
        "\n",
        "    entropy = 0.\n",
        "    if len(y) != 0 :\n",
        "\n",
        "        #calulate the probability of examples that have 1\n",
        "        p = len(y[y == 1]) / len(y)\n",
        "        \n",
        "        if p != 0 and p != 1:\n",
        "            entropy = -p*np.log2(p)-(1-p)*np.log2(1-p)  # because we have two classes, p the proba if y=1, 1-p: the probe if y=0\n",
        "        else:\n",
        "            entropy = 0.\n",
        "\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "y16KRagaiMr2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2)  Split the dataset"
      ],
      "metadata": {
        "id": "t34Bdzu7nv1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, node_indices, feature):\n",
        "  \n",
        "    left_indices = []\n",
        "    right_indices = []\n",
        "\n",
        "    for i in node_indices:   \n",
        "       if X[i][feature] == 1: \n",
        "           left_indices.append(i)\n",
        "       else:\n",
        "           right_indices.append(i)\n",
        "\n",
        "    return left_indices, right_indices"
      ],
      "metadata": {
        "id": "ynAIcOV7oDjX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3)  Split the dataset"
      ],
      "metadata": {
        "id": "ql0g52sAN68t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_information_gain(X, y, node_indices, feature):\n",
        "  \n",
        "    # Split dataset\n",
        "    left_indices, right_indices = split_dataset(X, node_indices, feature)\n",
        "    \n",
        "    # Some useful variables\n",
        "    X_node, y_node   =  X[node_indices]  ,  y[node_indices]\n",
        "    X_left, y_left   =  X[left_indices]  ,  y[left_indices]\n",
        "    X_right, y_right =  X[right_indices] ,  y[right_indices]\n",
        "    \n",
        "    # You need to return the following variables correctly\n",
        "    information_gain = 0\n",
        "    \n",
        "    node_entropy =  compute_entropy  (y_node)\n",
        "    # Your code here to compute the entropy at the left branch\n",
        "    left_entropy =  compute_entropy  (y_left)\n",
        "    # Your code here to compute the entropy at the right branch\n",
        "    right_entropy = compute_entropy (y_right)\n",
        "    \n",
        "    w_left = len(X_left) / len(X_node)\n",
        "    w_right = len(X_right) / len(X_node)\n",
        "    \n",
        "    weighted_entropy = w_left*left_entropy + w_right*right_entropy\n",
        "    \n",
        "    information_gain = node_entropy - weighted_entropy\n",
        "    \n",
        "    return information_gain"
      ],
      "metadata": {
        "id": "bY24aekxOBPN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yTbMUWleOjN-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Get the best split"
      ],
      "metadata": {
        "id": "yd6iLD7iOkT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_split(X, y, node_indices):   \n",
        "     \n",
        "    # Some useful variables\n",
        "    num_features = X.shape[1]\n",
        "    \n",
        "    # You need to return the following variables correctly\n",
        "    best_feature = -1\n",
        "    \n",
        "    max_info_gain = 0\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    for feature in range(num_features): \n",
        "\n",
        "       # Your code here to compute the information gain from splitting on this feature\n",
        "       info_gain = compute_information_gain(X,y, node_indices,feature)\n",
        "\n",
        "       # If the information gain is larger than the max seen so far\n",
        "       if info_gain > max_info_gain:  \n",
        "           # Your code here to set the max_info_gain and best_feature\n",
        "           max_info_gain = info_gain\n",
        "           best_feature = feature\n",
        "\n",
        "    ### END CODE HERE ##    \n",
        "    return best_feature"
      ],
      "metadata": {
        "id": "YAI0YHHfOnkd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Building the tree"
      ],
      "metadata": {
        "id": "efuKUIzdRe_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not graded\n",
        "tree = [] \n",
        "\n",
        "def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth): \n",
        "   \n",
        "    # Maximum depth reached - stop splitting \n",
        "    if current_depth == max_depth: \n",
        "        formatting = \" \"*current_depth + \"-\"*current_depth \n",
        "        print(formatting, \"%s leaf node with indices\" % branch_name, node_indices) \n",
        "        return \n",
        "   \n",
        "    # Otherwise, get best split and split the data \n",
        "    # Get the best feature and threshold at this node \n",
        "    best_feature = get_best_split(X, y, node_indices) \n",
        "    \n",
        "    formatting = \"-\"*current_depth \n",
        "    print( \"%s Depth %d, %s: Split on feature: %d\" % (formatting, current_depth, branch_name, best_feature)) \n",
        "    \n",
        "    # Split the dataset at the best feature \n",
        "    left_indices, right_indices = split_dataset(X, node_indices, best_feature)  \n",
        "    tree.append((left_indices, right_indices, best_feature)) \n",
        "    \n",
        "    # continue splitting the left and the right child. Increment current depth \n",
        "    build_tree_recursive(X, y, left_indices, \"Left\", max_depth, current_depth+1) \n",
        "    build_tree_recursive(X, y, right_indices, \"Right\", max_depth, current_depth+1) "
      ],
      "metadata": {
        "id": "LeYKDcy5RnBc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHia3fpoalbq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) Testing our algorithm"
      ],
      "metadata": {
        "id": "lTJbF-Khg_iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
        "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
      ],
      "metadata": {
        "id": "V4yXHr0mhGXU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "build_tree_recursive(X_train, y_train, root_indices, \"Root\", max_depth=2, current_depth=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gS2HHbQMABa",
        "outputId": "2a9c22b7-f366-4dcf-b8f3-2ac763e38c4b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Depth 0, Root: Split on feature: 2\n",
            "- Depth 1, Left: Split on feature: 0\n",
            "  -- Left leaf node with indices [0, 1, 4, 7]\n",
            "  -- Right leaf node with indices [5]\n",
            "- Depth 1, Right: Split on feature: 1\n",
            "  -- Left leaf node with indices [8]\n",
            "  -- Right leaf node with indices [2, 3, 6, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_oaNEhSNtmE",
        "outputId": "4c89d99e-4a67-4652-b284-93b6a235dfeb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([0, 1, 4, 5, 7], [2, 3, 6, 8, 9], 2),\n",
              " ([0, 1, 4, 7], [5], 0),\n",
              " ([8], [2, 3, 6, 9], 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sv6tYV3PTHqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}